# VQ VAE model
vq_vae_model_path: './src/T2M_GPT_lightning/models/vqvae/weights/vq_vae_model.pth'

# Gpt model
model_hyperparameters:
  num_vq: 32 # Number of quantized vectors
  embed_dim: 512
  clip_dim: 512
  block_size: 100
  num_layers: 2
  n_heads: 8
  drop_out_rate: 0.1
  fc_rate: 4
  learning_rate: 0.000004

# Trainer
is_toy: True
batch_size: 1
max_epochs: 2000
save_weights_path: './t2m_trans.pth'
train_text_path: './data/toy_data/train.text'
train_skels_path: './data/toy_data/train.skels'
val_text_path: './data/toy_data/train.text'
val_skels_path: './data/toy_data/train.skels'
